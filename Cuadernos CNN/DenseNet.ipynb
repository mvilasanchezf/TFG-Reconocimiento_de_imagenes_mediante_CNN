{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "465239b6-2922-4ef7-b462-7e3c57f67236",
   "metadata": {},
   "source": [
    "# DenseNet161\n",
    "\n",
    "## 1. Importamos librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81eec07a-cdf4-422f-af36-e2ca6262bb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple, Dict, List\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3b6b69-2422-4256-8162-797a539d4651",
   "metadata": {},
   "source": [
    "## 2. Definimos parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5aecc8f2-6c01-404f-844b-7a18d078dd15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x1f389d9ff90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = './data'\n",
    "img_size = (224, 224)\n",
    "bs = 16\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_epochs = 10\n",
    "output_size = 10000\n",
    "learning_rate = 0.0001\n",
    "show_every_n_batches = 1\n",
    "\n",
    "# Creamos un diccionario vacio para almacenar los resultados\n",
    "results = {'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_loss': [],\n",
    "        'val_acc': []\n",
    "    }\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # modo interactivo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646466c2-05b7-4efa-b0e5-9bd6076569ec",
   "metadata": {},
   "source": [
    "## Definimos el parámetro transform\n",
    "\n",
    "Vamos a cargar el conjunto de datos y sobre estos datos vamos a aplicar una serie de transformaciones previas:\n",
    "\n",
    "* Redimensionamos todas las imágenes al mismo tamaño (224x224).\n",
    "* Aleatoriamente se aplica un giro horizontal de la imagen.\n",
    "* Rotamos la imagen 10 grados de forma aleatoria.\n",
    "* Los trasformaremos en tensores y normalizamos $\\frac{x-mean}{std}$\n",
    "\n",
    "Inicialmente, vamos a aplicar la misma transformación al conjunto de datos de entrenamiento que al conjunto de datos de validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64911e06-2c02-4a21-83fe-ff84d4e10496",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(img_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(degrees=10),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(img_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(degrees=10),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2f9773-9736-4517-8ac4-82355c3aadb1",
   "metadata": {},
   "source": [
    "### Carga los datos de iNaturalist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc0a4b75-98de-40d0-8c87-270f067f30d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 500000, 'val': 100000}\n"
     ]
    }
   ],
   "source": [
    "image_datasets = {\n",
    "    x: datasets.INaturalist(\n",
    "        root = data_dir,\n",
    "        version = '2021_train_mini' if x == 'train' else '2021_valid',\n",
    "        transform = data_transforms[x],\n",
    "        download = False\n",
    "    )\n",
    "    for x in ['train', 'val']\n",
    "}\n",
    "dataloaders = {\n",
    "    x: torch.utils.data.DataLoader(\n",
    "        image_datasets[x],\n",
    "        batch_size = bs,\n",
    "        shuffle = True,\n",
    "        num_workers = 4\n",
    "    )\n",
    "    for x in ['train', 'val']\n",
    "}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "print(dataset_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da3fa77-62a7-43ef-8b4e-2ea715017b05",
   "metadata": {},
   "source": [
    "## Definimos la función de entrenamiento\n",
    "\n",
    "Función que realiza el entrenamiento para un modelo de red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "100dd34c-b9c3-4cb1-83ce-4d7134a68911",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=20):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Etapa {epoch + 1}/{num_epochs}')\n",
    "        print('-' * 11)\n",
    "\n",
    "        # Cada iteración tiene una fase de validación y una fase de entrenamiento\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Establece el modelo en modo entrenamiento\n",
    "            else:\n",
    "                model.eval()   # Establece el modelo en modo validación\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Itera sobre los datos\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # pone a cero los gradientes de los tensores optimizados\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # track historial adelante solo en la fase de entrenamiento\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Solo si está en la fase de entrenamiento retroceder + optimizar\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # estatisticas\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            if phase == 'train':\n",
    "                tittle = 'Entrenamiento'\n",
    "                results[\"train_loss\"].append(epoch_loss)\n",
    "                results[\"train_acc\"].append(epoch_acc.item())\n",
    "            else:\n",
    "                tittle = 'Validación'\n",
    "                results[\"val_loss\"].append(epoch_loss)\n",
    "                results[\"val_acc\"].append(epoch_acc.item())\n",
    "            print(f'{tittle}\\t{(time.time() - since)//60:.0f}min {(time.time() - since)%60:.0f}seg\\tPerdida: {epoch_loss:.4f}\\tPrecisión: {epoch_acc:.4f}')\n",
    "            \n",
    "            # copia del modelo con mejor porcentaje de acierto en la validación\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    if time_elapsed < 3600:\n",
    "        print(f'Entrenamiento completado en: {time_elapsed // 60:.0f}min. {time_elapsed % 60:.0f}seg.')\n",
    "    else:\n",
    "        rest_elapsed = time_elapsed % 3600\n",
    "        print(f'Entrenamiento completado en: {time_elapsed // 3600:.0f}horas {rest_elapsed // 60:.0f}min. {rest_elapsed % 60:.0f}seg.')\n",
    "    print(f'Mejor precisión validación: {best_acc:4f}')\n",
    "\n",
    "    # guarda los mejores pesos del modelo\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68af2970-6497-433b-abdc-a84346a76a8c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Definimos la clase clasificador"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0309f80c-ab36-4f83-b8fc-34f572da595a",
   "metadata": {},
   "source": [
    "## DenseNet-161 preentrenado\n",
    "\n",
    "Este modelo consta de dos partes principales: las características y el clasificador. La parte de las características es una pila de capas convolucionales y, en general, funciona como un detector de características que puede alimentar a un clasificador. La parte del clasificador es una única capa totalmente conectada (clasificador): Linear(in_features=2208, out_features=10000). Esta capa fue entrenada en el conjunto de datos ImageNet, por lo que no funcionará para nuestro problema específico. Eso significa que necesitamos reemplazar el clasificador, pero las características funcionarán perfectamente por sí solas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6c688ae-a268-44a0-942d-2ef6d781adce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.densenet161(weights='IMAGENET1K_V1')\n",
    "num_ftrs = model.classifier.in_features\n",
    "\n",
    "# Alternatively, it can be generalized to ``nn.Linear(num_ftrs, len(class_names))``.\n",
    "model.classifier = nn.Linear(num_ftrs, 10000)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Se optimizan todos los parámetros\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Se decrementa LR por un factor 0.1 cada 7 iteraciones\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ef5ad1-d592-4081-a112-57c54e5ecdac",
   "metadata": {},
   "source": [
    "## Entrenamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "493535c5-c64f-4f8c-b40c-d533fa931955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etapa 1/10\n",
      "-----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m train_model(model, criterion, optimizer, exp_lr_scheduler,\n\u001b[0;32m      2\u001b[0m                        num_epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[5], line 41\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[0;32m     38\u001b[0m             optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     40\u001b[0m     \u001b[39m# estatisticas\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m     running_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem() \u001b[39m*\u001b[39m inputs\u001b[39m.\u001b[39;49msize(\u001b[39m0\u001b[39;49m)\n\u001b[0;32m     42\u001b[0m     running_corrects \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msum(preds \u001b[39m==\u001b[39m labels\u001b[39m.\u001b[39mdata)\n\u001b[0;32m     43\u001b[0m \u001b[39mif\u001b[39;00m phase \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = train_model(model, criterion, optimizer, exp_lr_scheduler,\n",
    "                       num_epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
